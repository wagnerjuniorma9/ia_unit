{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Atividade.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"EewDSgrwLLL7","colab_type":"text"},"cell_type":"markdown","source":["# Inteligência Artificial e Redes Neurais \n","\n","## Atividade\n"]},{"metadata":{"id":"sSkHDJ7oMnXe","colab_type":"code","colab":{}},"cell_type":"code","source":["# Carregar datasets\n","!wget http://www.data2learning.com/ml_datasets/dataset1_1.pkl\n","!wget http://www.data2learning.com/ml_datasets/dataset1_2.pkl\n","!wget http://www.data2learning.com/ml_datasets/dataset2.pkl\n","!wget http://www.data2learning.com/ml_datasets/dataset3.pkl\n","!wget http://www.data2learning.com/ml_datasets/sentimentdataset.pkl"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C3Qu77W8OBES","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PxsQlATsLLL9","colab_type":"text"},"cell_type":"markdown","source":["# Tutorial\n","\n","A seguir está descrito todo o código necessário para executar os problemas práticos da atividade. \n","\n","## Instanciando os Modelos\n","\n","\n","### KNN\n","```python\n","knnmodel = KNeighborsClassifier(n_neighbors=3)\n","```\n","\n","O parâmetro **n_neightbors** corresponde ao valor de K vizinhos do algoritmo KNN. Ele pode ser variado.\n","\n","### Regressão Linear\n","```python\n","lm = LinearRegression()\n","```\n","\n","### Árvore de Decisão\n","```python\n","tree_model = tree.DecisionTreeClassifier(criterion='entropy',random_state=0)\n","```\n","\n","### SVM\n","```python\n","clfsvm = svm.SVC(kernel=kernel, C=C, random_state=0)\n","```\n","\n","Pode variar o kernel ('linear', 'poly', 'rbf', 'sigmoid') e o valor de C. No kernel *rbf* pode variar o parâmetro *gamma* e no *poly* pode variar o parâmetro *degree*. \n","\n","### Naive Bayes \n","\n","\n","naivemodel = GaussianNB()\n","\n","\n","### Rede Neural Perceptron\n","```python\n","perceptron_ = perceptron.Perceptron(n_iter=100, eta0=0.001, random_state=0, verbose=False)\n","```\n","\n","Pode variar o número de iterações (*n_iter*) e a taxa de aprendizagem (*eta0*).\n","\n","### Rede Neural MLP \n","\n","```python\n","mlp_ = MLPClassifier(\n","    hidden_layer_sizes=(256), \n","    activation='relu', \n","    batch_size=10, \n","    verbose=False, \n","    max_iter=120, \n","    learning_rate_init=0.001,\n","    random_state=0,\n","    alpha=0.1\n",")\n","```\n","Pode variar o tamanho e número de camadas (*hidden_layer_size*):\n","\n","* (256): 1 camada com 256 neurônios;\n","* (256, 256): 2 camadas com 256 neurônios cada;\n","* ... \n","\n","Pode variar a função de ativação (*activation*):\n","\n","* Valores possíveis: 'identity', 'logistic', 'tanh', 'relu'\n","\n","Pode variar o número de iterações (*max_iter*). \n","\n","Pode variar a taxa de aprendizagem (*learning_rate_init*)\n","\n","\n","## Treinando os Modelos\n","\n","Um modelo pode ser treinado utilizando o método FIT. Isso serve para qualquer modelo do Scikit-Learn. \n","\n","```python\n","modelo.fit(X, Y) #X = atributos, Y = a classe (ou labels)\n","```\n","\n","## Predição\n","\n","```python\n","modelo.predict(Z)\n","```\n","\n","Z é uma instância de teste. Por exemplo, se sua base possui três atributos que correspondem as características daquelas instâncias, o método predict tem que receber três atributos também na hora de fazer a predição. Ou seja, Z seria algo do tipo [10, 2.4, 3.1], por exemplo.\n","\n","## Divisão Treino/Teste\n","\n","```python\n","X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n","```\n","\n","onde *test_size* é a porcentagem de divisão. No exemplo, 20% da base é de teste e o restante é de treinamento. *X* são os dados (instâncias e atributos) e *y* a classe de cada instância. *random_state* é o controle do aleatório. Deve-se manter 4. \n","\n","\n","## Avaliação\n","\n","O modelo pode ser avaliado usando o método *score*.\n","\n","```python\n","modelo.score(X, y)\n","```\n","\n","Para que este método funcione, o modelo deve ser treinado antes (usando o *fit*).\n","\n","\n","## Validação Cruzada\n","\n","Uma outra forma de analisarmos o modelo construído é utilizando a validação cruzada. Para usá-la utilizamos: \n","\n","```python \n","scores = cross_val_score(MODELO, X, Y, cv=10, scoring='accuracy')\n","```\n","\n","* onde o MODELO é a instância do modelo que estamos criando (Arvore de Decisão, Regressão Linear, Rede Neural etc)\n","* X e Y são os dados com os atributos (X) e somente a coluna de resultado (Y).\n","* cv = quantidade de folds \n","* scoring: métrica de avaliação. Utiilze **r2** se estiver trabalhando com Regressão Linear.\n","\n","Esse método já faz o processo de treinamento e teste ao mesmo tempo. Não é necessário utilizar o **Fit** quando chamamos ele. \n","\n","Para obter a média do score basta utilizar: \n","\n","```python\n","scores.mean()\n","```\n","\n","## Python\n","\n","Para fazer um for de um até N utilize a seguinte notação: \n","\n","```python\n","for n in range(1, N+1):\n","    print n\n","```\n","\n","Se desejar imprimir algo no console, utilize o método **print**\n","\n","```python\n","print(\"Teste\")\n","print(X)\n","```"]},{"metadata":{"id":"K13f3L_ALLL-","colab_type":"code","colab":{}},"cell_type":"code","source":["# Instalação do NLKT\n","\n","import nltk\n","nltk.download()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FdxxE4YvLLMF","colab_type":"code","colab":{}},"cell_type":"code","source":["# Imports Necessários\n","\n","#Bibliotecas\n","import nltk\n","import re\n","import pandas as pd\n","import numpy as np \n","import unicodedata\n","import matplotlib.pyplot as plt\n","from sklearn.externals import joblib\n","from nltk.tokenize import TweetTokenizer\n","from nltk.corpus import stopwords\n","\n","# Modelos \n","from sklearn.neighbors import KNeighborsClassifier # KNN\n","from sklearn import tree # Arvore de Decisao\n","from sklearn import svm # SVM\n","from sklearn.naive_bayes import GaussianNB # Naive Bayes\n","from sklearn.ensemble import RandomForestClassifier # Random Forest\n","from sklearn.linear_model import perceptron\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.linear_model import LinearRegression\n","from sklearn.cluster import KMeans\n","\n","#Avaliação\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import train_test_split\n","\n","#stopwords\n","portuguese_stop = stopwords.words(['portuguese'])\n","\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IjPzGmRgLLMI","colab_type":"text"},"cell_type":"markdown","source":["### Funções de Suporte 1\n","\n","As funções a seguir são de suporte para diversas tarefas que foram realizadas na realização da prova. Para a realização da prova não é preciso usá-las. No entanto, a célula deve ser executada para garantir a execução da prova sem erros."]},{"metadata":{"id":"gtFpz2ApLLMJ","colab_type":"code","colab":{}},"cell_type":"code","source":["def strip_accents(text):\n","\n","    try:\n","        text = unicode(text, 'utf-8')\n","    except NameError: # unicode is a default on python 3 \n","        pass\n","    \n","    text = unicodedata.normalize('NFD', text)\n","    text = text.encode('ascii', 'ignore')\n","    text = text.decode(\"utf-8\")\n","    return str(text)\n","\n","def tokenize_only(text):\n","    twtk = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n","    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n","    tokens = twtk.tokenize(text)\n","    #[word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n","    filtered_tokens = []\n","    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n","    for token in tokens:\n","        token = re.sub(r\"http\\S+\", \"\", token)\n","        token = re.sub(r\"[...]\",\"\", token)\n","        token = strip_accents(token)\n","        if token not in portuguese_stop and len(token) >= 2:\n","            \n","            filtered_tokens.append(token)\n","            #if re.search('[a-zA-Z]', token):\n","            #    filtered_tokens.append(token)\n","    return filtered_tokens"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UPtY6lakLLMM","colab_type":"text"},"cell_type":"markdown","source":["## **Questão 01:** \n","\n","Foram estudados dois tipos de aprendizagem supervisionada: classificação e regressão. Sobre este assunto, responda o que se pede: "]},{"metadata":{"id":"SPoVsyP8LLMO","colab_type":"text"},"cell_type":"markdown","source":["**a)** Diferencie **classificação** e **regressão**. Deixe claro na explicação, o que de fato diferencia as duas técnicas principalemente em relação aos problemas em que elas são aplicadas. "]},{"metadata":{"id":"3wuhQ4CcLLMO","colab_type":"text"},"cell_type":"markdown","source":["**b)** A seguir são apresentadas duas bases. Sua tarefa é analisar as informações da duas e aplicar o algoritmo correto para cada uma delas entre os algoritmos de **regressão linear** e **knn**. Na aplicação do algoritmo utilize a validação cruzada com 5 folds. Na aplicação da regressão linear reporte o valor da métrica **r2** e no caso do knn reporte a acurácia."]},{"metadata":{"id":"Vt9dWXorLLMQ","colab_type":"text"},"cell_type":"markdown","source":["### Base 1\n","\n","A base 1 é referenciada pelo trabalho \"Predicting social media performance metrics and evaluation of the impact on brand building: A data mining approach\"(Moro, 2016) e tem como objetivo prever a evolução de um post no facebook a partir de um conjunto de métricas coletadas dos posts. Na base, as *features* correspondem as métricas e o *label* (a coluna que deseja-se prever) corresponde a quantidade de iteração (comentários + curtidas +  compartilhamentos) de um post. "]},{"metadata":{"id":"SAPT_a61LLMQ","colab_type":"code","colab":{}},"cell_type":"code","source":["dataset1_1 = joblib.load(\"dataset1_1.pkl\")\n","dataset1_1['full'].head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jc4ob6oTLLMU","colab_type":"text"},"cell_type":"markdown","source":["### Base 2\n","\n","A base 2 é referenciada pelo trabalho \"Phishing Detection based Associative Classification Data Mining\" (Abdelhamid et al., 2014) e tem como objetivo identificar se um website sofreu um ataque de *pishing*. De forma geral, *Phishing* é um tipo de ataque que faz com que sites criados sejam substituídos por sites falsos, fazendo com que usuários passem informações sigilosas como CPF, logins, e-mails, senhas para criminosos. Nesta base, cada instância é um website que é classificado como Legitimate (1: site legítimo), Suspicious (0: suspeito) ou phishy (-1: sofreu pishing)."]},{"metadata":{"id":"Yts1pWQ8LLMW","colab_type":"code","colab":{}},"cell_type":"code","source":["dataset1_2 = joblib.load(\"dataset1_2.pkl\")\n","dataset1_2['full'].head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bHO0wt19LLMa","colab_type":"code","colab":{}},"cell_type":"code","source":["# Imports das Bases\n","\n","# Base 1\n","\n","X_base1 = dataset1_1['X']\n","Y_base1 = dataset1_1['y']\n","\n","# Base 2\n","\n","X_base2 = dataset1_2['X']\n","Y_base2 = dataset1_2['y']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aRdxgh37LLMc","colab_type":"code","colab":{}},"cell_type":"code","source":["print(X_base1.shape, Y_base1.shape)\n","print(X_base2.shape, Y_base2.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VV1b-RxqLLMg","colab_type":"code","colab":{}},"cell_type":"code","source":["# Insira a resposta da questão 1 a partir daqui"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WpKjn-1HLLMj","colab_type":"text"},"cell_type":"markdown","source":["## **Questão 02**: \n","\n","Uma árvore de decisão permite classificar um conjunto de dados a partir da divisão do espaço de busca de acordo com os valores dos atributos. Para cada nó da árvore, um atributo deve ser escolhido de forma que melhor separe o conjunto de dados. \n","\n","Sabendo que o **Ganho de Informação** é dado por: \n","\n","$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$, \n","\n","e a **Entropia** é dada por: \n","\n","$E = \\sum_{i}^{c}{-p_i\\log_2{p_i}}$\n","\n","Você deve mostrar a partir do cálculo do Ganho de Informação e da Entropia qual o melhor atributo para ser utilizado como raiz da árvore.\n","\n","**OBS: é obrigatório apresentar os cálculos realizados.**"]},{"metadata":{"id":"_4pTT9mvLLMk","colab_type":"code","colab":{}},"cell_type":"code","source":["dataset2 = joblib.load(\"dataset2.pkl\")\n","dataset2"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kTQm7DW7LLMp","colab_type":"text"},"cell_type":"markdown","source":["*Insira a resposta da questão 2 aqui* "]},{"metadata":{"id":"-KIiBccSLLMt","colab_type":"text"},"cell_type":"markdown","source":["## **Questão 03:** \n","\n","Os algoritmos de SVM e Naive Bayes são dois clássicos algoritmos supervisionados. Ambos se valem de conceitos interessantes da matemática para construir os modelos de aprendizagem. Sobre estes algoritmos, responda:\n","\n","**a)** Explique, brevemente, os conceitos por trás destes dois algoritmos. Deixe claro na sua explicação quais conceitos matemáticos estudados em sala de aula são utilizados na construção de cada um dos modelos.\n","\n","**b)** Aplique os dois algoritmos na base a seguir. Analise os resultados obtidos nas configurações padrões do algoritmo e depois modifique os parâmetros do melhor algoritmo para se obter um resultado melhor do que o anterior. Os testes devem ser realizados utilizando validação cruzada de 5 folds. A análise deve ser feita a partir destes valores. "]},{"metadata":{"id":"Wxx3ZmlnLLMt","colab_type":"code","colab":{}},"cell_type":"code","source":["dataset3 = joblib.load(\"dataset3.pkl\")\n","X = dataset3['X']\n","Y = dataset3['Y']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tELkFfNPLLMy","colab_type":"code","colab":{}},"cell_type":"code","source":["X.head()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mK8o8p28LLM1","colab_type":"code","colab":{}},"cell_type":"code","source":["# Responda a questão 3 a partir daqui"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bpftbufSLLM8","colab_type":"text"},"cell_type":"markdown","source":["## Questão 04\n","\n","Você foi contratado por uma empresa para construir um sistema que permite analisar automaticamente um conjunto de tweets e determinar se o mesmo é classificado como positivo ou negativo. Sabendo que você tem uma base de dados pré-classificada de tweets positivos e tweets negativos em português. Responda o que se pede.\n","\n","**a)** Proponha um conjunto de tarefas que você deve realizar para atender o objetivo para o qual você foi contratado. Deixe claro cada um dos procedimentos que serão tomados e porque usa-lo. Deixe claro como você pode maximizar as chances de de construir um sistema como boa acurácia dentre os modelos que foram disponibilizados no início desta prova."]},{"metadata":{"id":"1HBn-equLLM9","colab_type":"text"},"cell_type":"markdown","source":["*Insira sua resposta a partir daqui* "]},{"metadata":{"id":"_nKCeWu2LLM-","colab_type":"text"},"cell_type":"markdown","source":["------\n","O código a seguir carrega a base de dados disponibilizada para executar os itens **b** e **c**. Leia com atenção a descrição completa da base. O seu entendimento é essencial para a realização das tarefas que seguem. "]},{"metadata":{"id":"gVgR91_DLLNA","colab_type":"code","colab":{}},"cell_type":"code","source":["# Carrega a base de dados\n","\n","'''\n","    A base de dados é composta por três componentes: \n","    \n","     sentiment_dataset['X']: matrix de instâncias e termos utilizado para treinamento do modelo. \n","     sentiment_dataset['y']: vetor de classes que indica a classe real de cada uma das instâncias \n","                             da base de treinamento. Na base, 0 é negativo e 1 é positivo. \n","     sentiment_dataset['vector']: modelo de vetorização da base de dados original. Isso deve ser utilizado \n","                                 na hora de analisar os novos dados como descrito a seguir.\n","\n","'''\n","\n","sentiment_dataset = joblib.load(\"sentimentdataset.pkl\")\n","X = sentiment_dataset['X']\n","y = sentiment_dataset['y']\n","vector = sentiment_dataset['vector']"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hXahxrEzLLNG","colab_type":"text"},"cell_type":"markdown","source":["**b)** Baseado no que você descreveu no **item a**, implemente um passo a passo para a construação de um modelo que permite reconhecer testes. Implemente alguns métodos, modifique os parâmetros e apresente como resposta a acurácia do melhor modelo. "]},{"metadata":{"id":"sz9ayZUOLLNI","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"jhcDoqfuLLNK","colab_type":"text"},"cell_type":"markdown","source":["**c)** Utilize o melhor modelo gerado no **item b** e use-o para analisar os textos a seguir. Para cada texto deve-se indicar a classe que o modelo classifica cada um. Na classificação, 1 é positivo e 0 é negativo. "]},{"metadata":{"id":"_az2Gy0CLLNK","colab_type":"code","colab":{}},"cell_type":"code","source":["'''\n","    Os textos a seguir devem ser classificados a partir do modelo que foi escolhido na questão anterior. Antes \n","    de fazer a predição, deve-se gerar X_new_ que nada mais é do que sua base de teste. O código a seguir transforma\n","    tal texto em uma matriz onde as linhas são as instâncias e as colunas as palavras que foram utilizadas na base\n","    de treinamento. \n","'''\n","\n","new_text = [\n","    'eu realmente acho que os produtos da apple sao otimos :)', \n","    'eu gosto de cantar <3', \n","    'triste noticia',\n","    'odeio esse produto :(',\n","    'eu nao gosto da saga crepusculo'\n","]\n","\n","X_new_ = vector.transform(new_text).toarray()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v8DnxSLaLLNN","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}